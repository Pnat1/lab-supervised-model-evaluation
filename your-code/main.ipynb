{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "linreg = LinReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = linreg.predict(X_test)\n",
    "y_pred_train = linreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - Determination Coeffiecient of test 0.6304410035910326\n",
      "R2 - Determination Coefficient of train 0.7653062658315821\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 - Determination Coeffiecient of test\", metrics.r2_score(y_test, y_pred_test))\n",
    "print(\"R2 - Determination Coefficient of train\", metrics.r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE - Mean Squarred Error of test 33.35363575570029\n",
      "MSE - Mean Squarred Error of test 19.348675657836527\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE - Mean Squarred Error of test\", metrics.mean_squared_error(y_test, y_pred_test))\n",
    "print(\"MSE - Mean Squarred Error of test\", metrics.mean_squared_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE - Mean Absolute Error 3.883339339078888\n",
      "MAE - Mean Absolute Error 3.089948464892908\n"
     ]
    }
   ],
   "source": [
    "print('MAE - Mean Absolute Error', metrics.mean_absolute_error(y_test, y_pred_test))\n",
    "print('MAE - Mean Absolute Error', metrics.mean_absolute_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     class  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillermo/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(data['class'])\n",
    "# Exaact amount of elements per each value of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series(y_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillermo/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = log.predict(X_test)\n",
    "y_pred_train = log.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test score of test  0.9666666666666667\n",
      "Accuracy test score of train  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "acc_y_test = accuracy_score(y_test, y_pred_test)\n",
    "acc_y_train = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Accuracy test score of test \", acc_y_test)\n",
    "print(\"Accuracy test score of train \", acc_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy test score of test  0.9743589743589745\n",
      "Balanced Accuracy test score of train  0.966108966108966\n"
     ]
    }
   ],
   "source": [
    "bal_y_test = balanced_accuracy_score(y_test, y_pred_test)\n",
    "bal_y_train = balanced_accuracy_score(y_train, y_pred_train)\n",
    "print(\"Balanced Accuracy test score of test \", bal_y_test)\n",
    "print(\"Balanced Accuracy test score of train \", bal_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision test score of test  0.9666666666666667\n",
      "Precision test score of train  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "prec_y_test = precision_score(y_test, y_pred_test, average='micro')\n",
    "prec_y_train = precision_score(y_train, y_pred_train, average='micro')\n",
    "print(\"Precision test score of test \", prec_y_test)\n",
    "print(\"Precision test score of train \", prec_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score of test : 0.9666666666666667\n",
      "Recall score of train : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "rec_y_test = recall_score(y_test,y_pred_test, average='micro')\n",
    "rec_y_train= recall_score(y_train, y_pred_train, average='micro')\n",
    "print('Recall score of test :', rec_y_test)\n",
    "print('Recall score of train :', rec_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of test : 0.9666666666666667\n",
      "F1 score of train : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "f1_y_test = recall_score(y_test,y_pred_test, average='micro')\n",
    "f1_y_train= recall_score(y_train, y_pred_train, average='micro')\n",
    "print('F1 score of test :', f1_y_test)\n",
    "print('F1 score of train :', f1_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0],\n",
       "       [ 0,  8,  0],\n",
       "       [ 0,  1, 12]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41,  0,  0],\n",
       "       [ 0, 40,  2],\n",
       "       [ 0,  2, 35]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'dis': LinearDiscriminantAnalysis(),\n",
    "    'neighbors': KNeighborsClassifier(),\n",
    "    'naive': GaussianNB(),\n",
    "    'tree': DecisionTreeClassifier(),\n",
    "    'svm': SVC(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING  dis\n",
      "TRAINING  neighbors\n",
      "TRAINING  naive\n",
      "TRAINING  tree\n",
      "TRAINING  svm\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(\"TRAINING \", name)\n",
    "    model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------dis--------\n",
      "Accuracy:  0.9666666666666667\n",
      "Precision:  0.9666666666666667\n",
      "Recall:  0.9666666666666667\n",
      "F1:  0.9666666666666667\n",
      "--------neighbors--------\n",
      "Accuracy:  0.9666666666666667\n",
      "Precision:  0.9666666666666667\n",
      "Recall:  0.9666666666666667\n",
      "F1:  0.9666666666666667\n",
      "--------naive--------\n",
      "Accuracy:  0.9666666666666667\n",
      "Precision:  0.9666666666666667\n",
      "Recall:  0.9666666666666667\n",
      "F1:  0.9666666666666667\n",
      "--------tree--------\n",
      "Accuracy:  0.9666666666666667\n",
      "Precision:  0.9666666666666667\n",
      "Recall:  0.9666666666666667\n",
      "F1:  0.9666666666666667\n",
      "--------svm--------\n",
      "Accuracy:  0.9666666666666667\n",
      "Precision:  0.9666666666666667\n",
      "Recall:  0.9666666666666667\n",
      "F1:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"--------{name}--------\")\n",
    "    print(\"Accuracy: \", accuracy_score(y_test,y_pred_test))\n",
    "    print(\"Precision: \", precision_score(y_test,y_pred_test, average='micro'))\n",
    "    print(\"Recall: \", recall_score(y_test,y_pred_test, average='micro'))\n",
    "    print(\"F1: \", f1_score(y_test, y_pred_test, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the exact same value with the other models of the lesson"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
